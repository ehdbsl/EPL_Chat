{"cells":[{"cell_type":"markdown","metadata":{"id":"Ij8hyklrOF_l"},"source":["# **1. 데이터 로드 및 전처리**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27972,"status":"ok","timestamp":1722389529515,"user":{"displayName":"황동현","userId":"05368631646559195403"},"user_tz":-540},"id":"-NupI0ozlMOQ","outputId":"76f15163-c7de-4428-9279-41276743abb3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1957,"status":"ok","timestamp":1722390466880,"user":{"displayName":"황동현","userId":"05368631646559195403"},"user_tz":-540},"id":"onqLtzIsXyW7"},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast, AdamW, get_linear_schedule_with_warmup\n","from tqdm import tqdm\n","import re\n","from sklearn.metrics import accuracy_score, f1_score\n","from sklearn.model_selection import train_test_split\n","import os"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":294,"referenced_widgets":["f97d44a047924a3693bcfd5d70f30e8e","280f2ad1630d40278c18c7f9dfcbc4c9","1058333f1db24d9cbd8cca2880487521","bab8566b1a504781aac35ce00ebe2ecf","c5e28de8522c4d819851a83a1d3c4f0e","681a8e3d222748b787571b766f9f381e","fdfedad62b9c4f09b99c79ddb1c10116","98cc252a6d1d4bd5b08d7ce26ffabc08","23dc4118bd9d4a098b2368ef213e01b6","e86c8ce2c3d144ebad8f49f89f6abd53","19c9ec1d08004e1b866b89e2a7f36554","55e59d84f4b942ef9b030603f10c4c79","b641e6ee03f249ba96b3f870522863ea","c05863be791b42169d887470b210dec8","c11eba6b8b09438095fe229e636d6193","d48e375977c8442c92682460147eafdd","98de79f5ec3449098896944df8244d9f","67641c11137e4e8d9031f7f52f936cf2","d24e4eb000d349bb93ec667806334c40","c53ea231995f4cccad3d20ec88d3e90a","79a2cd32d31d47969de130c953fa2a2a","506aff0a650046f49456df0a81f3e41b","e59c51b64b8b4505b25e87c89b441779","e71694fa263448df8b25c7ce90a21028","45486b62bbcd4412a5df50fc39eff869","1027bb59bebf45f0a600ddbcb32780fa","4fb694ff597c49e3ac08a93b06d85d0a","9be4362598a54e7f834e85c4aa82ec6e","4001e71b0846417fb7b6dee6a1744403","322fe670d54846c99fc70c1176fd01e9","28f3b4ee4c514832b24ecf813d950a15","3d4c02eddf534cbf9c8871c44e29dcdb","7e7ff5625fad4206b6a037d0347fb6fb"]},"executionInfo":{"elapsed":20450,"status":"ok","timestamp":1722390487325,"user":{"displayName":"황동현","userId":"05368631646559195403"},"user_tz":-540},"id":"ylKZ_7XeX7Io","outputId":"66cf1645-9185-4434-bea6-d2a84034df56"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f97d44a047924a3693bcfd5d70f30e8e","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55e59d84f4b942ef9b030603f10c4c79","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e59c51b64b8b4505b25e87c89b441779","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# 토크나이저 및 모델 로드\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")  # 토크나이저 로드\n","model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")  # 모델 로드\n","\n","# 패딩 토큰 추가\n","special_tokens = {'pad_token': '[PAD]'}\n","tokenizer.add_special_tokens(special_tokens)  # 패딩 토큰 추가\n","model.resize_token_embeddings(len(tokenizer))  # 토크나이저 크기 재조정\n","model.config.pad_token_id = tokenizer.pad_token_id  # 패딩 토큰 ID 설정"]},{"cell_type":"markdown","metadata":{"id":"NvwUWkDXYHSx"},"source":["## (1-1). 추가 학습 시"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gISrJQHbYGuY"},"outputs":[],"source":["# 모델 및 토크나이저 로드\n","model_path = \"/content/drive/MyDrive/fine_tuned_kogpt2\"\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path)\n","model = GPT2LMHeadModel.from_pretrained(model_path)\n","\n","# 패딩 토큰 추가\n","special_tokens = {'pad_token': '[PAD]'}\n","tokenizer.add_special_tokens(special_tokens)  # 패딩 토큰 추가\n","model.resize_token_embeddings(len(tokenizer))  # 토크나이저 크기 재조정\n","model.config.pad_token_id = tokenizer.pad_token_id  # 패딩 토큰 ID 설정"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1917,"status":"ok","timestamp":1722390494430,"user":{"displayName":"황동현","userId":"05368631646559195403"},"user_tz":-540},"id":"CUj2SODWN7Ir"},"outputs":[],"source":["# 데이터 로드 및 전처리\n","df = pd.read_csv('/content/drive/MyDrive/EPL.csv')  # CSV 파일에서 데이터 로드\n","df = df.dropna().drop_duplicates()  # 결측치와 중복 행 제거\n","\n","def clean_text(text):\n","    # 줄 바꿈 문자를 띄어쓰기로 대체\n","    text = re.sub(r'\\n', ' ', text)\n","    # 영문자, 한글, 숫자, 공백, 괄호, 물음표를 제외한 모든 문자 제거\n","    text = re.sub(r'[^a-zA-Z가-힣0-9\\s\\(\\)\\?]', '', text)\n","    # 연속된 공백을 하나의 공백으로 대체\n","    text = re.sub(r'\\s+', ' ', text)\n","    # 앞뒤 공백 제거\n","    return text.strip()\n","\n","df['Question'] = df['Question'].apply(clean_text)  # 질문 텍스트 정리\n","df['Answer'] = df['Answer'].apply(clean_text)  # 답변 텍스트 정리"]},{"cell_type":"markdown","metadata":{"id":"JPJcqxNxOTia"},"source":["# **2. 데이터셋 생성**"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1722390497508,"user":{"displayName":"황동현","userId":"05368631646559195403"},"user_tz":-540},"id":"HmVGW_eXOS3a"},"outputs":[],"source":["# 데이터셋 클래스 정의\n","class EPLDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_length=512):\n","        self.tokenizer = tokenizer  # 토크나이저 저장\n","        self.data = dataframe  # 데이터 저장\n","        self.max_length = max_length  # 최대 길이 설정\n","\n","    def __len__(self):\n","        return len(self.data)  # 데이터셋의 길이 반환\n","\n","    def __getitem__(self, index):\n","        question = self.data.iloc[index]['Question']  # 특정 인덱스의 질문 가져오기\n","        answer = self.data.iloc[index]['Answer']  # 특정 인덱스의 답변 가져오기\n","\n","        # 질문과 답변을 결합\n","        full_text = f\"질문: {question} 답변: {answer}\"\n","\n","        encoding = self.tokenizer.encode_plus(\n","            full_text,\n","            add_special_tokens=True,\n","            max_length=self.max_length,\n","            padding='max_length',\n","            truncation=True,\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","        input_ids = encoding['input_ids'].flatten()  # 인코딩된 input_ids\n","        attention_mask = encoding['attention_mask'].flatten()  # 인코딩된 attention_mask\n","\n","        return {\n","            'input_ids': input_ids,\n","            'attention_mask': attention_mask,\n","            'labels': input_ids  # 레이블도 input_ids와 동일하게 설정\n","        }\n","\n","# 데이터셋 분할\n","df = df.sample(frac=1, random_state=42).reset_index(drop=True)   # 데이터셋을 무작위로 섞기\n","\n","# 훈련 데이터와 검증 데이터로 분리\n","train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","train_dataset = EPLDataset(train_df, tokenizer)   # 학습 데이터셋 생성\n","val_dataset = EPLDataset(val_df, tokenizer)       # 검증 데이터셋 생성\n","\n","# 데이터 로더 생성\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)  # 학습 데이터 로더 생성\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)     # 검증 데이터 로더 생성"]},{"cell_type":"markdown","metadata":{"id":"EGbBL0I0OXHo"},"source":["# **3. 학습 및 평가 함수 설정**"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1722390503346,"user":{"displayName":"황동현","userId":"05368631646559195403"},"user_tz":-540},"id":"qsn26gRBOaUr","outputId":"2dd8e31a-1fe9-4309-8720-034403c60077"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}],"source":["# 학습 설정\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # GPU 또는 CPU 설정\n","model.to(device)  # 모델을 device로 이동\n","\n","optimizer = AdamW(model.parameters(), lr=5e-5)  # 옵티마이저 설정\n","num_epochs = 100  # 초기 epoch 수를 크게 설정\n","num_training_steps = num_epochs * len(train_loader)  # 전체 학습 스텝 수\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)  # 스케줄러 설정\n","\n","# 학습 함수\n","def train(model, dataloader, optimizer, scheduler, device):\n","    model.train()  # 모델을 학습 모드로 설정\n","    total_loss = 0  # 총 손실 초기화\n","    all_preds = []  # 모든 예측값 저장 리스트\n","    all_labels = []  # 모든 실제값 저장 리스트\n","    for batch in tqdm(dataloader):  # 배치마다 반복\n","        input_ids = batch['input_ids'].to(device)  # 배치의 input_ids를 device로 이동\n","        attention_mask = batch['attention_mask'].to(device)  # 배치의 attention_mask를 device로 이동\n","        labels = batch['labels'].to(device)  # 배치의 labels를 device로 이동\n","\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)  # 모델의 출력값\n","        loss = outputs.loss  # 손실값\n","\n","        total_loss += loss.item()  # 총 손실값에 더하기\n","\n","        loss.backward()  # 손실값으로 역전파\n","        optimizer.step()  # 옵티마이저 스텝\n","        scheduler.step()  # 스케줄러 스텝\n","        optimizer.zero_grad()  # 옵티마이저 그래디언트 초기화\n","\n","        # 예측 및 실제 레이블 저장 (평가를 위해)\n","        preds = torch.argmax(outputs.logits, dim=-1)\n","        all_preds.extend(preds.cpu().numpy().flatten())\n","        all_labels.extend(labels.cpu().numpy().flatten())\n","\n","    # 성능 지표 계산\n","    acc = accuracy_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    return total_loss / len(dataloader), acc, f1  # 평균 손실, 정확도, F1 점수 반환\n","\n","# 평가 함수\n","def evaluate(model, dataloader, device):\n","    model.eval()  # 모델을 평가 모드로 설정\n","    total_loss = 0  # 총 손실 초기화\n","    all_preds = []  # 모든 예측값 저장 리스트\n","    all_labels = []  # 모든 실제값 저장 리스트\n","    with torch.no_grad():  # 기울기 계산 비활성화\n","        for batch in dataloader:  # 배치마다 반복\n","            input_ids = batch['input_ids'].to(device)  # 배치의 input_ids를 device로 이동\n","            attention_mask = batch['attention_mask'].to(device)  # 배치의 attention_mask를 device로 이동\n","            labels = batch['labels'].to(device)  # 배치의 labels를 device로 이동\n","\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)  # 모델의 출력값\n","            loss = outputs.loss  # 손실값\n","\n","            total_loss += loss.item()  # 총 손실값에 더하기\n","\n","            # 예측 및 실제 레이블 저장 (평가를 위해)\n","            preds = torch.argmax(outputs.logits, dim=-1)\n","            all_preds.extend(preds.cpu().numpy().flatten())\n","            all_labels.extend(labels.cpu().numpy().flatten())\n","\n","    # 성능 지표 계산\n","    acc = accuracy_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    return total_loss / len(dataloader), acc, f1  # 평균 손실, 정확도, F1 점수 반환"]},{"cell_type":"markdown","metadata":{"id":"RUMnuluNOj64"},"source":["# **4. Early Stopping을 이용한 모델 학습**"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2068187,"status":"ok","timestamp":1722394587791,"user":{"displayName":"황동현","userId":"05368631646559195403"},"user_tz":-540},"id":"HQGmYOe6OtRL","outputId":"efb9ad22-49de-4fa8-d09d-351e4f8dca4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:34<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.3369, Accuracy: 0.8690, F1 Score: 0.8687\n","Validation Loss: 0.2511, Accuracy: 0.8462, F1 Score: 0.8451\n","Epoch 2/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:33<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.1609, Accuracy: 0.8732, F1 Score: 0.8720\n","Validation Loss: 0.1805, Accuracy: 0.8463, F1 Score: 0.8453\n","Epoch 3/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:33<00:00,  1.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.1110, Accuracy: 0.8732, F1 Score: 0.8721\n","Validation Loss: 0.1626, Accuracy: 0.8463, F1 Score: 0.8453\n","Epoch 4/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:33<00:00,  1.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0828, Accuracy: 0.8732, F1 Score: 0.8721\n","Validation Loss: 0.1274, Accuracy: 0.8462, F1 Score: 0.8452\n","Epoch 5/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:33<00:00,  1.58it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0654, Accuracy: 0.8731, F1 Score: 0.8721\n","Validation Loss: 0.1164, Accuracy: 0.8462, F1 Score: 0.8452\n","Model and tokenizer saved at epoch 5\n","Epoch 6/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:34<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0526, Accuracy: 0.8731, F1 Score: 0.8721\n","Validation Loss: 0.1068, Accuracy: 0.8462, F1 Score: 0.8450\n","Epoch 7/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:34<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0481, Accuracy: 0.8732, F1 Score: 0.8722\n","Validation Loss: 0.1166, Accuracy: 0.8462, F1 Score: 0.8453\n","Epoch 8/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:33<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0445, Accuracy: 0.8731, F1 Score: 0.8721\n","Validation Loss: 0.0993, Accuracy: 0.8463, F1 Score: 0.8453\n","Epoch 9/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:34<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0362, Accuracy: 0.8731, F1 Score: 0.8722\n","Validation Loss: 0.0967, Accuracy: 0.8463, F1 Score: 0.8452\n","Epoch 10/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:33<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0316, Accuracy: 0.8731, F1 Score: 0.8721\n","Validation Loss: 0.0977, Accuracy: 0.8462, F1 Score: 0.8453\n","Model and tokenizer saved at epoch 10\n","Epoch 11/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:33<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0306, Accuracy: 0.8731, F1 Score: 0.8722\n","Validation Loss: 0.0977, Accuracy: 0.8462, F1 Score: 0.8452\n","Epoch 12/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:34<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0315, Accuracy: 0.8731, F1 Score: 0.8722\n","Validation Loss: 0.1000, Accuracy: 0.8462, F1 Score: 0.8453\n","Epoch 13/100\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 431/431 [04:33<00:00,  1.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train Loss: 0.0290, Accuracy: 0.8731, F1 Score: 0.8722\n","Validation Loss: 0.1053, Accuracy: 0.8462, F1 Score: 0.8452\n","Early stopping\n","Final model and tokenizer saved.\n"]}],"source":["import os\n","import torch\n","from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n","\n","# Early Stopping 클래스\n","class EarlyStopping:\n","    def __init__(self, patience=3, min_delta=0):\n","        self.patience = patience  # 조기 중단을 결정하기까지 기다리는 기간\n","        self.min_delta = min_delta  # 최소 개선량\n","        self.counter = 0  # 카운터 초기화\n","        self.best_loss = None  # 최고의 손실값 초기화\n","        self.early_stop = False  # 조기 중단 플래그 초기화\n","\n","    def __call__(self, val_loss):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss  # 초기 손실값 설정\n","        elif val_loss > self.best_loss - self.min_delta:\n","            self.counter += 1  # 개선되지 않으면 카운터 증가\n","            if self.counter >= self.patience:\n","                self.early_stop = True  # 인내심 초과 시 조기 중단 플래그 설정\n","        else:\n","            self.best_loss = val_loss  # 새로운 최고의 손실값 업데이트\n","            self.counter = 0  # 카운터 초기화\n","\n","# 저장할 디렉토리 생성 (존재하지 않는 경우)\n","save_dir = '/content/drive/MyDrive/fine_tuned_kogpt2'\n","os.makedirs(save_dir, exist_ok=True)\n","\n","# 모델 학습\n","early_stopping = EarlyStopping(patience=5, min_delta=0.01)  # EarlyStopping 객체 생성, 인내심을 5로 설정하고 개선 최소값을 0.01로 설정\n","\n","num_epochs = 100  # 총 epoch 수\n","for epoch in range(num_epochs):  # 총 epoch 수만큼 반복\n","    print(f\"Epoch {epoch + 1}/{num_epochs}\")  # 현재 epoch 번호 출력\n","    train_loss, train_acc, train_f1 = train(model, train_loader, optimizer, scheduler, device)  # 학습 데이터셋에 대해 모델 학습 및 성능 평가\n","    val_loss, val_acc, val_f1 = evaluate(model, val_loader, device)  # 검증 데이터셋에 대해 모델 평가\n","\n","    # 학습 결과 출력\n","    print(f\"Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.4f}, F1 Score: {train_f1:.4f}\")\n","    print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}\")\n","\n","    early_stopping(val_loss)  # EarlyStopping 객체에 현재 검증 손실값 전달\n","    if early_stopping.early_stop:  # 조기 중단 플래그가 설정되었는지 확인\n","        print(\"Early stopping\")  # 조기 중단이 트리거되었음을 출력\n","        break  # 학습 중단\n","\n","    # 5 epoch마다 모델과 토크나이저 저장\n","    if (epoch + 1) % 5 == 0:\n","        model_save_path = os.path.join(save_dir, f\"model_epoch_{epoch + 1}\")\n","        tokenizer_save_path = os.path.join(save_dir, f\"tokenizer_epoch_{epoch + 1}\")\n","        model.save_pretrained(model_save_path)\n","        tokenizer.save_pretrained(tokenizer_save_path)\n","        print(f\"Model and tokenizer saved at epoch {epoch + 1}\")\n","\n","# 최종 모델과 토크나이저 저장\n","model.save_pretrained(save_dir)\n","tokenizer.save_pretrained(save_dir)\n","print(\"Final model and tokenizer saved.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AhUwfQLjXSPW"},"outputs":[],"source":["torch.save(model.state_dict(), os.path.join(save_dir, f'model_epoch_{epoch + 1}.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4438,"status":"ok","timestamp":1722338095654,"user":{"displayName":"황동현","userId":"05368631646559195403"},"user_tz":-540},"id":"yJ7erudNJJXK","outputId":"8a59f342-fa61-430a-8a7d-ddd334f4fcd5"},"outputs":[{"data":{"text/plain":["('/content/drive/MyDrive/fine_tuned/tokenizer_config.json',\n"," '/content/drive/MyDrive/fine_tuned/special_tokens_map.json',\n"," '/content/drive/MyDrive/fine_tuned/tokenizer.json')"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# 모델 저장\n","model.save_pretrained(\"/content/drive/MyDrive/fine_tuned\")\n","tokenizer.save_pretrained(\"/content/drive/MyDrive/fine_tuned\")"]},{"cell_type":"markdown","metadata":{"id":"HwqzH_OrUMN8"},"source":["# **5. 질문-답변 테스트**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31768,"status":"ok","timestamp":1722394837821,"user":{"displayName":"황동현","userId":"05368631646559195403"},"user_tz":-540},"id":"QNqoEvLpTozy","outputId":"88d5bc09-f24d-47e8-a145-2c0aff3ffc23"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/muru/miniforge3/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:588: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["질문: \n","답변: 아스톤빌라의 41번 선수는 제이콥 램지(Jacob Ramsey)입니다\n","질문: 첼시 감독\n","답변: 첼시의 감독은 엔초 마레스카 (Enzo Maresca)입니다 그는 탈리아의 축구 선수 출신으로 현재 첼시 FC의 감독을 맡고 있습니다\n","질문: 첼시 주장\n","답변: 첼시의 주장은 리스 제임스 (Reece James) 포지션 미드필더수비수 활약 기간 19531958 특징 맨유의 왼쪽 풀백으로 뛰었던 선수입니다\n","질문: 토트넘 홈구장\n","답변: 토트넘의 홈구장은 토트넘 홋스퍼 스타디움 (Tottenham Hotspur Stadium)입니다\n"]}],"source":["import torch\n","from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n","\n","# 모델 및 토크나이저 로드\n","model_path = \"./fine_tuned_kogpt2\"\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path)\n","model = GPT2LMHeadModel.from_pretrained(model_path)\n","\n","# 모델을 평가 모드로 전환\n","model.eval()\n","\n","# 테스트를 위해 입력을 받는 함수 정의\n","def generate_response(question, model, tokenizer, max_length=50):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    # 입력 텍스트 전처리\n","    input_text = f\"질문: {question} 답변:\"\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n","\n","    # 답변 생성\n","    with torch.no_grad():\n","        output = model.generate(\n","            input_ids,\n","            max_length=max_length,\n","            num_return_sequences=1,\n","            pad_token_id=tokenizer.pad_token_id,\n","            eos_token_id=tokenizer.eos_token_id,\n","            early_stopping=True\n","        )\n","\n","    # 출력 텍스트 디코딩\n","    response = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","    # \"답변:\" 이후의 텍스트만 추출\n","    response = response.split(\"답변:\")[1].strip()\n","\n","    return response\n","\n","# 질문과 답변 반복 루프\n","while True:\n","    question = input(\"질문을 입력하세요 (종료하려면 '종료'를 입력하세요): \")\n","    if question.lower() == '종료':\n","        break\n","\n","    response = generate_response(question, model, tokenizer)\n","    print(f\"질문: {question}\")\n","    print(f\"답변: {response}\")\n"]},{"cell_type":"markdown","metadata":{"id":"ckx8Wh7PTrSK"},"source":["# **6. 질문 생성 테스트**"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59331,"status":"ok","timestamp":1722395136886,"user":{"displayName":"황동현","userId":"05368631646559195403"},"user_tz":-540},"id":"Ly-WODgQvw6Y","outputId":"027921bd-7c55-4045-896e-6daf0863889a"},"outputs":[{"name":"stdout","output_type":"stream","text":["답변을 입력하세요 (종료하려면 '종료'를 입력하세요): 토트넘의 홈구장은 토트넘 홋스퍼 스타디움 (Tottenham Hotspur Stadium)입니다.\n","답변: 토트넘의 홈구장은 토트넘 홋스퍼 스타디움 (Tottenham Hotspur Stadium)입니다.\n","생성된 질문: 토트넘의 홈구장은 토트넘 홋스 (T\n","답변을 입력하세요 (종료하려면 '종료'를 입력하세요): 휴고 요리수\n","답변: 휴고 요리수\n","생성된 질문: 셰필드의 UEFA 랭킹은 몇 위야? 답변: 셰필드 유나이티드 FC의 UEFA 클럽 랭킹은 2024년 기준으로 132위입니다\n","답변을 입력하세요 (종료하려면 '종료'를 입력하세요): 휴고 요리스\n","답변: 휴고 요리스\n","생성된 질문: 토트넘의 200001 시즌 리그 클린시트왕은 누구야? 답변: 토트넘의 200001 시즌 리그 클린시트왕은 닐 설리번(Neil Sullivan)\n","답변을 입력하세요 (종료하려면 '종료'를 입력하세요): 종료\n"]}],"source":["import torch\n","from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n","\n","# 모델 및 토크나이저 로드\n","model_path = \"/content/drive/MyDrive/fine_tuned_kogpt2\"\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path)\n","model = GPT2LMHeadModel.from_pretrained(model_path)\n","\n","# 모델을 평가 모드로 전환\n","model.eval()\n","\n","# 퀴즈 질문을 생성하는 함수 정의\n","def generate_question(answer, model, tokenizer, max_length=50):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","\n","    # 입력 텍스트 전처리\n","    input_text = f\"답변: {answer} 질문:\"\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n","\n","    # 질문 생성\n","    with torch.no_grad():\n","        output = model.generate(\n","            input_ids,\n","            max_length=max_length,\n","            num_return_sequences=1,\n","            pad_token_id=tokenizer.pad_token_id,\n","            eos_token_id=tokenizer.eos_token_id,\n","            early_stopping=True\n","        )\n","\n","    # 출력 텍스트 디코딩\n","    question = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","    # \"질문:\" 이후의 텍스트만 추출\n","    question = question.split(\"질문:\")[1].strip()\n","\n","    return question\n","\n","# 질문과 답변 반복 루프 (퀴즈 기능)\n","while True:\n","    answer = input(\"답변을 입력하세요 (종료하려면 '종료'를 입력하세요): \")\n","    if answer.lower() == '종료':\n","        break\n","\n","    question = generate_question(answer, model, tokenizer)\n","    print(f\"답변: {answer}\")\n","    print(f\"생성된 질문: {question}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-UyyCz6vyjQ"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1027bb59bebf45f0a600ddbcb32780fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d4c02eddf534cbf9c8871c44e29dcdb","placeholder":"​","style":"IPY_MODEL_7e7ff5625fad4206b6a037d0347fb6fb","value":" 513M/513M [00:09&lt;00:00, 56.4MB/s]"}},"1058333f1db24d9cbd8cca2880487521":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_98cc252a6d1d4bd5b08d7ce26ffabc08","max":2825034,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23dc4118bd9d4a098b2368ef213e01b6","value":2825034}},"19c9ec1d08004e1b866b89e2a7f36554":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23dc4118bd9d4a098b2368ef213e01b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"280f2ad1630d40278c18c7f9dfcbc4c9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_681a8e3d222748b787571b766f9f381e","placeholder":"​","style":"IPY_MODEL_fdfedad62b9c4f09b99c79ddb1c10116","value":"tokenizer.json: 100%"}},"28f3b4ee4c514832b24ecf813d950a15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"322fe670d54846c99fc70c1176fd01e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d4c02eddf534cbf9c8871c44e29dcdb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4001e71b0846417fb7b6dee6a1744403":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45486b62bbcd4412a5df50fc39eff869":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_322fe670d54846c99fc70c1176fd01e9","max":513302779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28f3b4ee4c514832b24ecf813d950a15","value":513302779}},"4fb694ff597c49e3ac08a93b06d85d0a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"506aff0a650046f49456df0a81f3e41b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55e59d84f4b942ef9b030603f10c4c79":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b641e6ee03f249ba96b3f870522863ea","IPY_MODEL_c05863be791b42169d887470b210dec8","IPY_MODEL_c11eba6b8b09438095fe229e636d6193"],"layout":"IPY_MODEL_d48e375977c8442c92682460147eafdd"}},"67641c11137e4e8d9031f7f52f936cf2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"681a8e3d222748b787571b766f9f381e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79a2cd32d31d47969de130c953fa2a2a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e7ff5625fad4206b6a037d0347fb6fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"98cc252a6d1d4bd5b08d7ce26ffabc08":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98de79f5ec3449098896944df8244d9f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9be4362598a54e7f834e85c4aa82ec6e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b641e6ee03f249ba96b3f870522863ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98de79f5ec3449098896944df8244d9f","placeholder":"​","style":"IPY_MODEL_67641c11137e4e8d9031f7f52f936cf2","value":"config.json: 100%"}},"bab8566b1a504781aac35ce00ebe2ecf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e86c8ce2c3d144ebad8f49f89f6abd53","placeholder":"​","style":"IPY_MODEL_19c9ec1d08004e1b866b89e2a7f36554","value":" 2.83M/2.83M [00:01&lt;00:00, 2.14MB/s]"}},"c05863be791b42169d887470b210dec8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d24e4eb000d349bb93ec667806334c40","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c53ea231995f4cccad3d20ec88d3e90a","value":1000}},"c11eba6b8b09438095fe229e636d6193":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79a2cd32d31d47969de130c953fa2a2a","placeholder":"​","style":"IPY_MODEL_506aff0a650046f49456df0a81f3e41b","value":" 1.00k/1.00k [00:00&lt;00:00, 66.6kB/s]"}},"c53ea231995f4cccad3d20ec88d3e90a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5e28de8522c4d819851a83a1d3c4f0e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d24e4eb000d349bb93ec667806334c40":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d48e375977c8442c92682460147eafdd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e59c51b64b8b4505b25e87c89b441779":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e71694fa263448df8b25c7ce90a21028","IPY_MODEL_45486b62bbcd4412a5df50fc39eff869","IPY_MODEL_1027bb59bebf45f0a600ddbcb32780fa"],"layout":"IPY_MODEL_4fb694ff597c49e3ac08a93b06d85d0a"}},"e71694fa263448df8b25c7ce90a21028":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9be4362598a54e7f834e85c4aa82ec6e","placeholder":"​","style":"IPY_MODEL_4001e71b0846417fb7b6dee6a1744403","value":"pytorch_model.bin: 100%"}},"e86c8ce2c3d144ebad8f49f89f6abd53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f97d44a047924a3693bcfd5d70f30e8e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_280f2ad1630d40278c18c7f9dfcbc4c9","IPY_MODEL_1058333f1db24d9cbd8cca2880487521","IPY_MODEL_bab8566b1a504781aac35ce00ebe2ecf"],"layout":"IPY_MODEL_c5e28de8522c4d819851a83a1d3c4f0e"}},"fdfedad62b9c4f09b99c79ddb1c10116":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
